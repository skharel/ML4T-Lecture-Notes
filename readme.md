# GA Tech ML4T - CS7646 notes

[Syllabus for Fall 2021](http://lucylabs.gatech.edu/ml4t/fall2021/)
[Course home](http://lucylabs.gatech.edu/ml4t/)

# Love the course!

- This is definitely a well done class; take this class before you get into other AI/ML classes. You will learn a lot from here that will make your life easy on other classes.
- You will learn numpy, pandas, data cleaning and visualization in this course

# Image issue

I can't get images to render in GitHub (trust me all images are uploaded in images directory); if you can make it work, open up a PR.

Image rendering works locally (at least in VSCode for me; no clue on other IDEs)

# Lecture video

[Lecture is freely available for anyone!](https://omscs.gatech.edu/cs-7646-machine-learning-trading-course-videos)

https://omscs.gatech.edu/cs-7646-machine-learning-trading-course-videos

# Notes

## Week 1:

Hello Numpy and pandas!

- [1-1.ipynb](./1-1.ipynb)
- [1-2.ipynb](./1-2.ipynb)
- [1-3.ipynb](./1-3.ipynb)
- [1-4.ipynb](./1-4.ipynb)

## Week 2:

Optimizations:

- [1-5.ipynb](./1-5.ipynb)
- [1-6.ipynb](./1-6.ipynb)
- [1-7.ipynb](./1-7.ipynb)
- [1-8.ipynb](./1-8.ipynb)

## Week 3:

Intro to ML:

- [1-9.ipynb](./1-9.ipynb)
- [3-1.ipynb](./3-1.ipynb)
- [3-2.ipynb](./3-2.ipynb)

## Week 4:

- [Assessing learning Algorithm: 3-3.ipynb](./3-3.ipynb)
  - Fitting data
  - RMS Error
  - In sample vs out of sample
  - Cross validation, Roll forward cross validation
  - Correlation and RMS Error
  - Overfitting
    <br/>
- [Ensemble learners - bagging and boosting: 3-4.ipynb](./3-4.ipynb)

  - Ensemble
  - Bootstrap aggregating - bagging
  - Overfitting
  - Bagging example
  - Boosting
  - Overfitation

- [Decision Tree & Random forest: 3-5_decision_tree.ipynb](./3-5_decision_tree.ipynb)
  - 2 lecture videos
    - 1st part: what does the tree look like
    - 2nd part: building the tree
      - JR Quinlan's algorithm
      - A Cutler Algorithm
      - Random forest
